:

📌 Customer Churn Prediction
📖 Project Overview

This project focuses on predicting customer churn in a telecom dataset. By analyzing customer demographics, account details, service usage, and billing information, the goal is to identify factors influencing churn and build a machine learning model to predict it.

🎯 Aim

To analyze customer behavior and detect patterns in churn.

To build a predictive model that helps businesses reduce customer attrition.

🛠️ Tools & Technologies

Programming: Python

Libraries: Pandas, NumPy, Matplotlib, Seaborn, Scikit-learn

Model Used: Random Forest Classifier

📊 Dataset Description

Size: 7,043 rows × 21 columns

Features:

Demographics: Gender, SeniorCitizen, Partner, Dependents

Account Info: Tenure, Contract, Payment method, Paperless billing

Services: Internet service, Online security, Tech support, Streaming services, Phone service

Charges: Monthly charges, Total charges

Target Variable: Churn (Yes/No)

🚀 Approach

Data Cleaning: Handled missing values, corrected data types, removed inconsistencies.

Exploratory Data Analysis (EDA): Visualized churn distribution, tenure trends, and service usage.

Feature Engineering: Encoded categorical variables, processed numerical features.

Modeling: Applied Random Forest Classifier.

Evaluation: Used Accuracy, Precision, Recall, and F1-score for model assessment.

📈 Results

Achieved 79% accuracy in churn prediction.

Identified tenure, contract type, monthly charges, and payment method as major churn drivers.

Model provided actionable insights for customer retention strategies.

🖼️ Visualizations

Churn distribution across tenure and contract type.

Correlation heatmap of numerical features.

Service usage vs churn analysis.

⚡ How to Run

Clone the repository

git clone https://github.com/your-username/customer-churn-prediction.git
cd customer-churn-prediction


Install dependencies

pip install -r requirements.txt


Run Jupyter Notebook / Python script for analysis

jupyter notebook Customer_Churn.ipynb

📌 Future Improvements

Test additional models (XGBoost, LightGBM, Neural Networks).

Apply hyperparameter tuning for better performance.

Use feature importance for explainable AI.




